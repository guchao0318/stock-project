#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨æ•°æ®é‡‡é›†ç³»ç»Ÿä¸»ç¨‹åº

åŠŸèƒ½:
1. æ¯å¤©9:10åˆ†è‡ªåŠ¨é‡‡é›†æ·±åœ³å’Œä¸Šæµ·Aè‚¡æ•°æ®
2. å°†æ•°æ®å­˜å‚¨åˆ°Elasticsearchä¸­
3. æ”¯æŒæ‰‹åŠ¨æ‰§è¡Œæ•°æ®é‡‡é›†
4. æä¾›ç³»ç»ŸçŠ¶æ€æŸ¥è¯¢

ä½¿ç”¨æ–¹æ³•:
    python main.py [é€‰é¡¹]
    
é€‰é¡¹:
    --run-once      ç«‹å³æ‰§è¡Œä¸€æ¬¡æ•°æ®é‡‡é›†
    --daemon        ä»¥å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼è¿è¡Œ
    --status        æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
    --stop          åœæ­¢è¿è¡Œä¸­çš„è°ƒåº¦å™¨
    --schedule-time è®¾ç½®è°ƒåº¦æ—¶é—´ (æ ¼å¼: HH:MM)
    --help          æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
"""

import sys
import os
import argparse
import signal
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from utils.logger_config import setup_logger, get_logger
from scheduler.task_scheduler import StockDataScheduler
from core.data_collector.stock_collector import StockDataCollector
from core.data_collector.history_collector import HistoryDataCollector
from core.data_collector.realtime_collector import RealtimeDataCollector
from core.data_storage.es_storage import ElasticsearchStorage
from core.data_storage.daily_storage import DailyDataStorage
from storage.nine_turn_storage import NineTurnStorage
from config.settings import DATA_COLLECTION_CONFIG

# å…¨å±€å˜é‡
scheduler = None
logger = None


def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    global scheduler, logger
    
    if logger:
        logger.info(f"æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨åœæ­¢ç¨‹åº...")
    
    if scheduler:
        scheduler.stop()
    
    if logger:
        logger.info("ç¨‹åºå·²åœæ­¢")
    
    sys.exit(0)


def run_once():
    """ç«‹å³æ‰§è¡Œä¸€æ¬¡æ•°æ®é‡‡é›†"""
    global scheduler, logger
    
    logger.info("å¼€å§‹æ‰‹åŠ¨æ‰§è¡Œæ•°æ®é‡‡é›†")
    
    try:
        scheduler = StockDataScheduler()
        result = scheduler.run_once()
        
        if result:
            logger.info("æ•°æ®é‡‡é›†æ‰§è¡ŒæˆåŠŸ")
            
            # æ˜¾ç¤ºç»“æœç»Ÿè®¡
            status = scheduler.get_status()
            logger.info(f"å½“å‰æ•°æ®æ€»é‡: {status.get('data_count', 0)}æ¡")
            
            return True
        else:
            logger.error("æ•°æ®é‡‡é›†æ‰§è¡Œå¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨æ‰§è¡Œæ•°æ®é‡‡é›†å¼‚å¸¸: {str(e)}")
        return False
    finally:
        if scheduler:
            scheduler.stop()


def run_history_collection(start_date, end_date):
    """æ‰§è¡Œå†å²æ•°æ®é‡‡é›†
    
    Args:
        start_date (str): å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
        end_date (str): ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    """
    global logger
    
    logger.info(f"å¼€å§‹æ‰§è¡Œå†å²æ•°æ®é‡‡é›† ({start_date} åˆ° {end_date})")
    
    try:
        history_collector = HistoryDataCollector()
        
        print(f"ğŸš€ å¼€å§‹é‡‡é›†å†å²è¡Œæƒ…æ•°æ® ({start_date} åˆ° {end_date})")
        print("â³ è¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        # æ‰§è¡Œå†å²æ•°æ®é‡‡é›†
        result = history_collector.collect_all_history_data(
            start_date=start_date,
            end_date=end_date,
            batch_size=50,
            delay_between_requests=1
        )
        
        # æ˜¾ç¤ºç»“æœ
        if result['total'] > 0:
            success_rate = (result['success'] / result['total']) * 100
            print(f"\nğŸ“Š å†å²æ•°æ®é‡‡é›†å®Œæˆ:")
            print(f"   æ€»è®¡: {result['total']} ä¸ªè‚¡ç¥¨")
            print(f"   æˆåŠŸ: {result['success']} ä¸ª ({success_rate:.1f}%)")
            print(f"   å¤±è´¥: {result['failed']} ä¸ª")
            
            if result['success'] > 0:
                print(f"âœ… å†å²æ•°æ®é‡‡é›†æˆåŠŸ")
                return True
            else:
                print(f"âŒ æ‰€æœ‰è‚¡ç¥¨çš„å†å²æ•°æ®é‡‡é›†éƒ½å¤±è´¥äº†")
                return False
        else:
            print("âŒ æœªæ‰¾åˆ°éœ€è¦é‡‡é›†çš„è‚¡ç¥¨")
            return False
        
    except Exception as e:
        logger.error(f"å†å²æ•°æ®é‡‡é›†å¤±è´¥: {str(e)}")
        print(f"âŒ å†å²æ•°æ®é‡‡é›†å¤±è´¥: {str(e)}")
        return False


def run_history_collection_by_api(start_date, end_date, stock_codes_str=None, adjust_flag="qfq"):
    """é€šè¿‡æ¥å£è¿è¡Œå†å²æ•°æ®é‡‡é›†
    
    Args:
        start_date (str): å¼€å§‹æ—¥æœŸ
        end_date (str): ç»“æŸæ—¥æœŸ
        stock_codes_str (str): è‚¡ç¥¨ä»£ç å­—ç¬¦ä¸²ï¼Œç”¨é€—å·åˆ†éš”
        adjust_flag (str): å¤æƒæ–¹å¼
        
    Returns:
        bool: é‡‡é›†æ˜¯å¦æˆåŠŸ
    """
    try:
        logger.info(f"å¼€å§‹é€šè¿‡æ¥å£é‡‡é›†å†å²æ•°æ® ({start_date} åˆ° {end_date})ï¼Œå¤æƒæ–¹å¼: {adjust_flag}")
        
        # å¤„ç†è‚¡ç¥¨ä»£ç åˆ—è¡¨
        stock_codes = None
        if stock_codes_str:
            stock_codes = [code.strip() for code in stock_codes_str.split(',') if code.strip()]
            logger.info(f"æŒ‡å®šè‚¡ç¥¨ä»£ç : {stock_codes}")
        else:
            logger.info("æœªæŒ‡å®šè‚¡ç¥¨ä»£ç ï¼Œå°†ä»ESè·å–å…¨éƒ¨è‚¡ç¥¨ä»£ç ")
        
        # åˆ›å»ºè°ƒåº¦å™¨å®ä¾‹
        scheduler = StockDataScheduler()
        
        # æ‰§è¡Œå†å²æ•°æ®é‡‡é›†
        result = scheduler.setup_history_schedule_once(
            start_date=start_date,
            end_date=end_date,
            stock_codes=stock_codes,
            adjust_flag=adjust_flag,
            execute_now=True
        )
        
        if result['total'] > 0:
            success_rate = (result['success'] / result['total']) * 100
            logger.info(f"æ¥å£å†å²æ•°æ®é‡‡é›†å®Œæˆ: æˆåŠŸç‡ {success_rate:.1f}% ({result['success']}/{result['total']})")
            return True
        else:
            logger.error("æ¥å£å†å²æ•°æ®é‡‡é›†å¤±è´¥: æ²¡æœ‰å¤„ç†ä»»ä½•æ•°æ®")
            return False
            
    except Exception as e:
        logger.error(f"æ¥å£å†å²æ•°æ®é‡‡é›†å¼‚å¸¸: {str(e)}")
        return False


def start_api_server():
    """å¯åŠ¨HTTP APIæœåŠ¡å™¨"""
    try:
        logger.info("å¯åŠ¨HTTP APIæœåŠ¡å™¨")
        
        from app.app import start_api_server as start_flask_server
        
        # å¯åŠ¨Flaskåº”ç”¨
        return start_flask_server(
            host='0.0.0.0',
            port=5000,
            debug=False
        )
        
    except Exception as e:
        logger.error(f"APIæœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {str(e)}")
        return False


def run_realtime_collection():
    """æ‰§è¡Œå®æ—¶è¡Œæƒ…æ•°æ®é‡‡é›†"""
    global logger
    
    logger.info("å¼€å§‹æ‰§è¡Œå®æ—¶è¡Œæƒ…æ•°æ®é‡‡é›†")
    
    try:
        realtime_collector = RealtimeDataCollector()
        
        print("ğŸš€ å¼€å§‹é‡‡é›†å®æ—¶è¡Œæƒ…æ•°æ®")
        print("â³ æ­£åœ¨è·å–å®æ—¶è¡Œæƒ…æ•°æ®...")
        
        # æ‰§è¡Œå®æ—¶æ•°æ®é‡‡é›†
        result = realtime_collector.collect_all_realtime_data()
        
        # æ˜¾ç¤ºç»“æœ
        if result['total'] > 0:
            success_rate = (result['success'] / result['total']) * 100
            print(f"\nğŸ“Š å®æ—¶æ•°æ®é‡‡é›†å®Œæˆ:")
            print(f"   æ€»è®¡: {result['total']} ä¸ªè‚¡ç¥¨")
            print(f"   æˆåŠŸ: {result['success']} ä¸ª ({success_rate:.1f}%)")
            print(f"   å¤±è´¥: {result['failed']} ä¸ª")
            
            if result['success'] > 0:
                print(f"âœ… å®æ—¶æ•°æ®é‡‡é›†æˆåŠŸ")
                return True
            else:
                print(f"âŒ æ‰€æœ‰è‚¡ç¥¨çš„å®æ—¶æ•°æ®é‡‡é›†éƒ½å¤±è´¥äº†")
                return False
        else:
            print("âŒ æœªæ‰¾åˆ°éœ€è¦é‡‡é›†çš„è‚¡ç¥¨")
            return False
        
    except Exception as e:
        logger.error(f"å®æ—¶æ•°æ®é‡‡é›†å¤±è´¥: {str(e)}")
        print(f"âŒ å®æ—¶æ•°æ®é‡‡é›†å¤±è´¥: {str(e)}")
        return False


def query_nine_turn_signals(date_from=None, date_to=None, stock_code=None, market_type=None):
    """æŸ¥è¯¢ä¹è½¬ç­–ç•¥ä¿¡å·
    
    Args:
        date_from (str): å¼€å§‹æ—¥æœŸ
        date_to (str): ç»“æŸæ—¥æœŸ
        stock_code (str): è‚¡ç¥¨ä»£ç 
        market_type (str): å¸‚åœºç±»å‹
    """
    global logger
    
    logger.info("æŸ¥è¯¢ä¹è½¬ç­–ç•¥ä¿¡å·")
    
    try:
        storage = NineTurnStorage()
        signals = storage.query_strategy_signals(
            date_from=date_from,
            date_to=date_to,
            stock_code=stock_code,
            market_type=market_type,
            limit=50
        )
        
        if signals:
            print(f"\nğŸ“Š æ‰¾åˆ° {len(signals)} æ¡ä¹è½¬ç­–ç•¥ä¿¡å·:")
            print("-" * 80)
            for signal in signals:
                print(f"æ—¥æœŸ: {signal['date']}, è‚¡ç¥¨: {signal['stock_code']}, "
                      f"å¸‚åœº: {signal['market_type']}, å½“å‰ä»·: {signal['current_price']/100:.2f}, "
                      f"å¯¹æ¯”ä»·: {signal['compare_price']/100:.2f}, "
                      f"æ¶¨å¹…: {signal['price_change_pct']/100:.2f}%")
        else:
            print("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä¹è½¬ç­–ç•¥ä¿¡å·")
            
        storage.close()
        
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ä¹è½¬ç­–ç•¥ä¿¡å·å¤±è´¥: {str(e)}")
        print(f"âŒ æŸ¥è¯¢ä¹è½¬ç­–ç•¥ä¿¡å·å¤±è´¥: {str(e)}")


def query_data(stock_code=None, limit=10, data_type='basic'):
    """æŸ¥è¯¢æ•°æ®
    
    Args:
        stock_code (str): è‚¡ç¥¨ä»£ç ï¼Œå¯é€‰
        limit (int): è¿”å›è®°å½•æ•°é™åˆ¶
        data_type (str): æ•°æ®ç±»å‹ï¼Œ'basic' æˆ– 'daily'
    """
    global logger
    
    logger.info(f"å¼€å§‹æŸ¥è¯¢{data_type}æ•°æ®ï¼Œè‚¡ç¥¨ä»£ç : {stock_code}, é™åˆ¶: {limit}")
    
    try:
        if data_type == 'daily':
            # æŸ¥è¯¢æ—¥çº¿æ•°æ®
            storage = DailyDataStorage()
            
            if stock_code:
                results = storage.search_daily_data(stock_code=stock_code, size=limit)
                print(f"\nğŸ“Š è‚¡ç¥¨ {stock_code} çš„æ—¥çº¿æ•°æ®:")
            else:
                results = storage.search_daily_data(size=limit)
                print(f"\nğŸ“Š æœ€æ–° {limit} æ¡æ—¥çº¿æ•°æ®:")
            
            if results:
                print(f"æ‰¾åˆ° {len(results)} æ¡è®°å½•:\n")
                for i, data in enumerate(results, 1):
                    print(f"{i:2d}. {data.get('date', 'N/A'):10s} | "
                          f"{data.get('stock_code', 'N/A'):8s} | "
                          f"å¼€ç›˜: {data.get('open_price', 0)/100:6.2f} | "
                          f"æ”¶ç›˜: {data.get('close_price', 0)/100:6.2f} | "
                          f"æ¶¨è·Œ: {data.get('change_percent', 0)/100:5.2f}%")
            else:
                print("æœªæ‰¾åˆ°åŒ¹é…çš„æ—¥çº¿æ•°æ®")
            
            # æ˜¾ç¤ºæ€»æ•°æ®é‡
            total_count = storage.get_daily_data_count()
            print(f"\nğŸ“ˆ æ•°æ®åº“ä¸­å…±æœ‰ {total_count} æ¡æ—¥çº¿è®°å½•")
            
        else:
            # æŸ¥è¯¢åŸºç¡€æ•°æ®
            storage = ElasticsearchStorage()
            
            if stock_code:
                results = storage.search_stock(stock_code=stock_code, size=limit)
                print(f"\nğŸ“Š è‚¡ç¥¨ {stock_code} çš„åŸºç¡€æ•°æ®:")
            else:
                results = storage.search_stock(size=limit)
                print(f"\nğŸ“Š æœ€æ–° {limit} æ¡åŸºç¡€æ•°æ®:")
            
            if results:
                print(f"æ‰¾åˆ° {len(results)} æ¡è®°å½•:\n")
                for i, stock in enumerate(results, 1):
                    print(f"{i:2d}. {stock.get('stock_code', 'N/A'):8s} | "
                          f"{stock.get('stock_name', 'N/A'):12s} | "
                          f"{stock.get('market_type', 'N/A'):8s} | "
                          f"ä»·æ ¼: {stock.get('current_price', 'N/A'):8s} | "
                          f"æ¶¨è·Œ: {stock.get('change_percent', 'N/A'):6s}%")
            else:
                print("æœªæ‰¾åˆ°åŒ¹é…çš„åŸºç¡€æ•°æ®")
            
            # æ˜¾ç¤ºæ€»æ•°æ®é‡
            total_count = storage.get_stock_count()
            print(f"\nğŸ“ˆ æ•°æ®åº“ä¸­å…±æœ‰ {total_count} æ¡åŸºç¡€è®°å½•")
        
        storage.close()
        
    except Exception as e:
        logger.error(f"æŸ¥è¯¢æ•°æ®å¤±è´¥: {str(e)}")
        print(f"âŒ æŸ¥è¯¢æ•°æ®å¤±è´¥: {str(e)}")


def run_daemon():
    """ä»¥å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼è¿è¡Œ"""
    global scheduler, logger
    
    logger.info("å¯åŠ¨è‚¡ç¥¨æ•°æ®é‡‡é›†å®ˆæŠ¤è¿›ç¨‹")
    
    try:
        scheduler = StockDataScheduler()
        scheduler.start()
        
        logger.info("å®ˆæŠ¤è¿›ç¨‹å¯åŠ¨æˆåŠŸï¼ŒæŒ‰Ctrl+Cåœæ­¢")
        
        # ä¸»å¾ªç¯
        while True:
            try:
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
                # å®šæœŸè¾“å‡ºçŠ¶æ€ä¿¡æ¯
                if datetime.now().minute % 10 == 0:  # æ¯10åˆ†é’Ÿè¾“å‡ºä¸€æ¬¡
                    status = scheduler.get_status()
                    logger.info(f"ç³»ç»Ÿè¿è¡Œä¸­ - ä¸‹æ¬¡æ‰§è¡Œ: {status.get('next_run', 'N/A')}, æ•°æ®é‡: {status.get('data_count', 0)}æ¡")
                    
            except KeyboardInterrupt:
                logger.info("æ¥æ”¶åˆ°åœæ­¢ä¿¡å·")
                break
            except Exception as e:
                logger.error(f"å®ˆæŠ¤è¿›ç¨‹è¿è¡Œå¼‚å¸¸: {str(e)}")
                time.sleep(60)
                
    except Exception as e:
        logger.error(f"å¯åŠ¨å®ˆæŠ¤è¿›ç¨‹å¼‚å¸¸: {str(e)}")
        return False
    finally:
        if scheduler:
            scheduler.stop()
    
    return True


def show_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
    global logger
    
    logger.info("æŸ¥è¯¢ç³»ç»ŸçŠ¶æ€")
    
    try:
        scheduler = StockDataScheduler()
        status = scheduler.get_status()
        
        print("\n=== è‚¡ç¥¨æ•°æ®é‡‡é›†ç³»ç»ŸçŠ¶æ€ ===")
        print(f"è¿è¡ŒçŠ¶æ€: {'è¿è¡Œä¸­' if status.get('is_running') else 'å·²åœæ­¢'}")
        print(f"è°ƒåº¦æ—¶é—´: {status.get('schedule_time')}")
        print(f"ä¸‹æ¬¡æ‰§è¡Œ: {status.get('next_run', 'æœªè®¾ç½®')}")
        print(f"ä»»åŠ¡æ•°é‡: {status.get('jobs_count', 0)}")
        print(f"æ•°æ®æ€»é‡: {status.get('data_count', 0)}æ¡")
        print(f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("==============================\n")
        
        scheduler.stop()
        return True
        
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ç³»ç»ŸçŠ¶æ€å¼‚å¸¸: {str(e)}")
        return False


def update_schedule_time(new_time: str):
    """æ›´æ–°è°ƒåº¦æ—¶é—´"""
    global logger
    
    logger.info(f"æ›´æ–°è°ƒåº¦æ—¶é—´ä¸º: {new_time}")
    
    try:
        # éªŒè¯æ—¶é—´æ ¼å¼
        datetime.strptime(new_time, '%H:%M')
        
        # æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„æ—¶é—´
        DATA_COLLECTION_CONFIG['schedule_time'] = new_time
        
        logger.info(f"è°ƒåº¦æ—¶é—´å·²æ›´æ–°ä¸º: {new_time}")
        logger.info("è¯·é‡å¯ç¨‹åºä»¥ä½¿æ–°çš„è°ƒåº¦æ—¶é—´ç”Ÿæ•ˆ")
        
        return True
        
    except ValueError:
        logger.error(f"æ— æ•ˆçš„æ—¶é—´æ ¼å¼: {new_time}ï¼Œåº”ä¸ºHH:MMæ ¼å¼")
        return False
    except Exception as e:
        logger.error(f"æ›´æ–°è°ƒåº¦æ—¶é—´å¼‚å¸¸: {str(e)}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    global logger
    
    # è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(
        description='è‚¡ç¥¨æ•°æ®é‡‡é›†ç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""ä½¿ç”¨ç¤ºä¾‹:
  python main.py --run-once          # ç«‹å³æ‰§è¡Œä¸€æ¬¡æ•°æ®é‡‡é›†
  python main.py --daemon            # ä»¥å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼è¿è¡Œ
  python main.py --status            # æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
  python main.py --query             # æŸ¥è¯¢æœ€æ–°åŸºç¡€æ•°æ®
  python main.py --query --stock 000001  # æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨åŸºç¡€æ•°æ®
  python main.py --query-daily       # æŸ¥è¯¢æœ€æ–°æ—¥çº¿æ•°æ®
  python main.py --query-daily --stock 000001  # æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨æ—¥çº¿æ•°æ®
  python main.py --history           # é‡‡é›†å†å²æ•°æ®(é»˜è®¤2025-08-17åˆ°2025-09-17)
  python main.py --history --start-date 2025-08-01 --end-date 2025-08-31  # æŒ‡å®šæ—¥æœŸèŒƒå›´
  python main.py --history-api       # é€šè¿‡æ¥å£é‡‡é›†å†å²æ•°æ®(ä»ESè·å–å…¨éƒ¨è‚¡ç¥¨)
  python main.py --history-api --stock-codes 000001,000002 --adjust-flag hfq  # æŒ‡å®šè‚¡ç¥¨å’Œå¤æƒæ–¹å¼
  python main.py --start-api         # å¯åŠ¨HTTP APIæœåŠ¡å™¨(ç«¯å£5000)
  python main.py --schedule-time 09:30    # è®¾ç½®è°ƒåº¦æ—¶é—´ä¸º09:30"""
    )
    
    parser.add_argument('--run-once', action='store_true', help='ç«‹å³æ‰§è¡Œä¸€æ¬¡æ•°æ®é‡‡é›†')
    parser.add_argument('--daemon', action='store_true', help='ä»¥å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼è¿è¡Œ')
    parser.add_argument('--status', action='store_true', help='æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€')
    parser.add_argument('--query', action='store_true', help='æŸ¥è¯¢åŸºç¡€æ•°æ®')
    parser.add_argument('--query-daily', action='store_true', help='æŸ¥è¯¢æ—¥çº¿æ•°æ®')
    parser.add_argument('--query-signals', action='store_true', help='æŸ¥è¯¢ä¹è½¬ç­–ç•¥ä¿¡å·')
    parser.add_argument('--history', action='store_true', help='é‡‡é›†å†å²è¡Œæƒ…æ•°æ®')
    parser.add_argument('--history-api', action='store_true', help='é€šè¿‡æ¥å£é‡‡é›†å†å²è¡Œæƒ…æ•°æ®')
    parser.add_argument('--start-api', action='store_true', help='å¯åŠ¨HTTP APIæœåŠ¡å™¨')
    parser.add_argument('--realtime', action='store_true', help='é‡‡é›†å®æ—¶è¡Œæƒ…æ•°æ®')
    parser.add_argument('--stock', type=str, help='æŒ‡å®šè‚¡ç¥¨ä»£ç è¿›è¡ŒæŸ¥è¯¢')
    parser.add_argument('--stock-codes', type=str, help='æŒ‡å®šè‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš” (å¦‚: 000001,000002,600000)')
    parser.add_argument('--adjust-flag', type=str, default='qfq', choices=['qfq', 'hfq', ''], help='å¤æƒæ–¹å¼: qfqå‰å¤æƒ, hfqåå¤æƒ, ç©ºå­—ç¬¦ä¸²ä¸å¤æƒ (é»˜è®¤: qfq)')
    parser.add_argument('--limit', type=int, default=10, help='æŸ¥è¯¢ç»“æœæ•°é‡é™åˆ¶ (é»˜è®¤: 10)')
    parser.add_argument('--start-date', type=str, default='2025-08-17', help='å†å²æ•°æ®å¼€å§‹æ—¥æœŸ (é»˜è®¤: 2025-08-17)')
    parser.add_argument('--end-date', type=str, default='2025-09-17', help='å†å²æ•°æ®ç»“æŸæ—¥æœŸ (é»˜è®¤: 2025-09-17)')
    parser.add_argument('--date-from', type=str, help='æŸ¥è¯¢å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--date-to', type=str, help='æŸ¥è¯¢ç»“æŸæ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--schedule-time', type=str, help='è®¾ç½®è°ƒåº¦æ—¶é—´ (æ ¼å¼: HH:MM)')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        setup_logger()
        logger = get_logger('main')
        
        logger.info("è‚¡ç¥¨æ•°æ®é‡‡é›†ç³»ç»Ÿå¯åŠ¨")
        logger.info(f"Pythonç‰ˆæœ¬: {sys.version}")
        logger.info(f"å·¥ä½œç›®å½•: {os.getcwd()}")
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        # æ ¹æ®å‚æ•°æ‰§è¡Œç›¸åº”æ“ä½œ
        if args.run_once:
            success = run_once()
            sys.exit(0 if success else 1)
            
        elif args.status:
            success = show_status()
            sys.exit(0 if success else 1)
            
        elif args.query:
            query_data(stock_code=args.stock, limit=args.limit, data_type='basic')
            
        elif args.query_daily:
            query_data(stock_code=args.stock, limit=args.limit, data_type='daily')
            
        elif args.history:
            success = run_history_collection(args.start_date, args.end_date)
            sys.exit(0 if success else 1)
            
        elif args.history_api:
            success = run_history_collection_by_api(
                args.start_date, 
                args.end_date, 
                args.stock_codes, 
                args.adjust_flag
            )
            sys.exit(0 if success else 1)
            
        elif args.start_api:
            success = start_api_server()
            sys.exit(0 if success else 1)
            
        elif args.realtime:
            success = run_realtime_collection()
            sys.exit(0 if success else 1)
            
        elif args.query_signals:
            query_nine_turn_signals(
                date_from=args.date_from,
                date_to=args.date_to,
                stock_code=args.stock,
                market_type=None
            )
            
        elif args.schedule_time:
            success = update_schedule_time(args.schedule_time)
            sys.exit(0 if success else 1)
            
        elif args.daemon:
            success = run_daemon()
            sys.exit(0 if success else 1)
            
        else:
            # é»˜è®¤æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
            parser.print_help()
            print("\nç¤ºä¾‹ç”¨æ³•:")
            print("  python main.py --run-once          # ç«‹å³æ‰§è¡Œä¸€æ¬¡æ•°æ®é‡‡é›†")
            print("  python main.py --daemon            # å¯åŠ¨å®ˆæŠ¤è¿›ç¨‹")
            print("  python main.py --status            # æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
            print("  python main.py --query             # æŸ¥è¯¢åŸºç¡€æ•°æ®")
            print("  python main.py --query-daily       # æŸ¥è¯¢æ—¥çº¿æ•°æ®")
            print("  python main.py --query-signals     # æŸ¥è¯¢ä¹è½¬ç­–ç•¥ä¿¡å·")
            print("  python main.py --history           # é‡‡é›†å†å²æ•°æ®")
            print("  python main.py --history-api       # é€šè¿‡æ¥å£é‡‡é›†å†å²æ•°æ®")
        print("  python main.py --history-api --stock-codes 000001,000002 --adjust-flag hfq  # æŒ‡å®šè‚¡ç¥¨å’Œå¤æƒæ–¹å¼")
        print("  python main.py --start-api         # å¯åŠ¨HTTP APIæœåŠ¡å™¨")
        print("  python main.py --realtime          # é‡‡é›†å®æ—¶è¡Œæƒ…æ•°æ®")
        print("  python main.py --schedule-time 09:30  # è®¾ç½®è°ƒåº¦æ—¶é—´ä¸º9:30")
            
    except KeyboardInterrupt:
        if logger:
            logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        if logger:
            logger.error(f"ç¨‹åºè¿è¡Œå¼‚å¸¸: {str(e)}")
        else:
            print(f"ç¨‹åºè¿è¡Œå¼‚å¸¸: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()